{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/bhawesh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack, vstack\n",
    "import csv\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import nltk\n",
    "import string\n",
    "import contractions\n",
    "nltk.download('wordnet')\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^a-z ]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "stemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower()# lowercase text\n",
    "    text = \" \".join([contractions.fix(t) for t in text.split(' ')])\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)# replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = re.sub(BAD_SYMBOLS_RE, '', text)# delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join([word.strip(string.punctuation) for word in text.split(' ')])\n",
    "    text = ' '.join([t for t in text.split(\" \") if len(t) > 2])\n",
    "    text = ' '.join([stemmer.lemmatize(x) for x in text.split() if x not in STOPWORDS])# delete stopwords from text\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhawesh/.local/lib/python3.5/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "goog_embed = \"/usr/workspace/tutorial/DL/Natural-Language-Processing/week3/data/GoogleNews-vectors-negative300.bin\"\n",
    "wv_embeddings = KeyedVectors.load_word2vec_format(datapath(goog_embed), binary=True, limit=500000)\n",
    "def question_to_vec(question, embeddings, dim=300):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        embeddings: dict where the key is a word and a value is its' embedding\n",
    "        dim: size of the representation\n",
    "\n",
    "        result: vector representation for the question\n",
    "    \"\"\"\n",
    "    ######################################\n",
    "    ######### YOUR CODE HERE #############\n",
    "    ######################################\n",
    "    count = 0\n",
    "    vec = np.zeros(dim)\n",
    "    for word in question.split(\" \"):\n",
    "        if word in embeddings:\n",
    "            count += 1\n",
    "            vec += embeddings[word]\n",
    "    if count == 0:\n",
    "        return vec\n",
    "    return vec/count\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-positive, 1-negative, 2-neutral\n",
    "df = pd.read_csv(\"inno/train.csv\")\n",
    "# print(df[\"text\"].iloc[0])\n",
    "df[\"text\"] = df[\"text\"].apply(text_prepare)\n",
    "# print(df[\"text\"])\n",
    "x = df[[\"text\", \"drug\"]]\n",
    "train_y = df[\"sentiment\"]\n",
    "train_x = df[\"text\"] + ' ' + df[\"drug\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec approach\n",
    "question2vec_result = []\n",
    "for con in range(len(train_x)):\n",
    "#     question = question.strip()\n",
    "    answer = question_to_vec(train_x.iloc[con], wv_embeddings)\n",
    "    question2vec_result.append(answer)\n",
    "    \n",
    "# tfidf = TfidfVectorizer(ngram_range=(1,2))\n",
    "# features = tfidf.fit_transform(np.array(train_x)) #fit transform to learn vocubulary and transform in matrix\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1,3))\n",
    "features1 = tfidf.fit_transform(np.array(x[\"text\"])) #fit transform to learn vocubulary and transform in matrix\n",
    "# features_test = tfidf.transform(np.array(testing_phrase[\"text\"])) #uses vocab from fit and transform to matrix\n",
    "features2 = tfidf.transform(np.array(x[\"drug\"]))\n",
    "features = hstack([features1, features2])\n",
    "\n",
    "regressor = RandomForestRegressor(n_jobs=-1, n_estimators=100)\n",
    "\n",
    "# regressor.fit(features, np.array(train_y))\n",
    "regressor.fit(np.array(question2vec_result), np.array(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100building tree 2 of 100building tree 3 of 100building tree 4 of 100\n",
      "\n",
      "\n",
      "\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf = TfidfVectorizer(ngram_range=(1,2))\n",
    "# features = tfidf.fit_transform(np.array(train_x)) #fit transform to learn vocubulary and transform in matrix\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=5, max_df=0.5, ngram_range=(1,3))\n",
    "features1 = tfidf.fit_transform(np.array(x[\"text\"])) #fit transform to learn vocubulary and transform in matrix\n",
    "# features_test = tfidf.transform(np.array(testing_phrase[\"text\"])) #uses vocab from fit and transform to matrix\n",
    "features2 = tfidf.transform(np.array(x[\"drug\"]))\n",
    "features = hstack([features1, features2])\n",
    "\n",
    "regressor = RandomForestRegressor(n_jobs=-1, n_estimators=100, verbose=2)\n",
    "\n",
    "regressor.fit(features, np.array(train_y))\n",
    "# regressor.fit(np.array(question2vec_result), np.array(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# tfidf approach\n",
    "df1 = pd.read_csv(\"inno/test.csv\")\n",
    "df1[\"text\"] = df1[\"text\"].apply(text_prepare)\n",
    "x1 = df1[\"text\"] + ' ' + df1[\"drug\"]\n",
    "y1 = df[\"sentiment\"]\n",
    "\n",
    "# feature1 = tfidf.transform(x1)\n",
    "\n",
    "features3 = tfidf.transform(np.array(df1[\"text\"]))\n",
    "features4 = tfidf.transform(np.array(df1[\"drug\"]))\n",
    "features11 = hstack([features3, features4])\n",
    "\n",
    "x3 = regressor.predict(features11)\n",
    "\n",
    "x4 = pd.DataFrame({'unique_hash':np.array(df1[\"unique_hash\"]), 'sentiment':x3})\n",
    "x4[\"sentiment\"] = x4[\"sentiment\"].apply(lambda x:int(round(x)))\n",
    "x4.to_csv(\"inno/sub15.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec approach\n",
    "df1 = pd.read_csv(\"inno/test.csv\")\n",
    "df1[\"text\"] = df1[\"text\"].apply(text_prepare)\n",
    "x1 = df1[\"text\"] + ' ' + df1[\"drug\"]\n",
    "y1 = df[\"sentiment\"]\n",
    "\n",
    "# feature1 = tfidf.transform(x1)\n",
    "\n",
    "# features3 = tfidf.transform(np.array(df1[\"text\"]))\n",
    "# features4 = tfidf.transform(np.array(df1[\"drug\"]))\n",
    "# features11 = hstack([features3, features4])\n",
    "\n",
    "question2vec_result1 = []\n",
    "for con1 in range(len(x1)):\n",
    "#     question = question.strip()\n",
    "    answer1 = question_to_vec(x1.iloc[con1], wv_embeddings)\n",
    "    question2vec_result1.append(answer1)\n",
    "\n",
    "x3 = regressor.predict(np.array(question2vec_result1))\n",
    "\n",
    "x4 = pd.DataFrame({'unique_hash':np.array(df1[\"unique_hash\"]), 'sentiment':x3})\n",
    "x4[\"sentiment\"] = x4[\"sentiment\"].apply(lambda x:int(round(x)))\n",
    "x4.to_csv(\"inno/sub12.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testit = []\n",
    "testit.append(question_to_vec(\"hello how are you\", wv_embeddings))\n",
    "testit.append(question_to_vec(\"hello how\", wv_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 300)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(testit).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autoimmune disease tend come cluster gilenya f...</td>\n",
       "      <td>gilenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>completely understand would want try result re...</td>\n",
       "      <td>gilenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interesting target receptor rather like fingol...</td>\n",
       "      <td>fingolimod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interesting grand merci wonder lemtrada ocrevu...</td>\n",
       "      <td>ocrevus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>everybody latest mri result brain cervical cor...</td>\n",
       "      <td>gilenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>give advice lemtrada chose cladribine thought ...</td>\n",
       "      <td>cladribine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>reply posted jesszidek jess sorry read challen...</td>\n",
       "      <td>humira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>well expected neurologist want start tysabri k...</td>\n",
       "      <td>gilenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>think fingolimod miserable failure progressive...</td>\n",
       "      <td>fingolimod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>thank much learning lot grace mentioned husban...</td>\n",
       "      <td>tagrisso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vision one eye unrelated eye injection however...</td>\n",
       "      <td>lucentis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>significant bleeding right eye need laser poss...</td>\n",
       "      <td>pan-retinal photocoagulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>objective review evidence supporting european ...</td>\n",
       "      <td>fingolimod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>multiple sclerosis thought inflammatory proces...</td>\n",
       "      <td>gilenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mom diagnosis similar mine detected january ch...</td>\n",
       "      <td>tagrisso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>humira adalimumab injectable protein antibody ...</td>\n",
       "      <td>humira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>well theory telling accurate standard practice...</td>\n",
       "      <td>remicade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>goodness minnie really wish could use curse wo...</td>\n",
       "      <td>stelara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sebastian agreed entirely know alemtuzumab due...</td>\n",
       "      <td>ocrelizumab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>good luck reg day ago went listen top neuro sp...</td>\n",
       "      <td>ocrevus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bmc ophthalmol jan intravitreal dexamethasone ...</td>\n",
       "      <td>dexamethasone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>father egfr exon insertion mutation found toda...</td>\n",
       "      <td>pemetrexed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>reply posted flower girl year got pregnant dau...</td>\n",
       "      <td>cimzia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hello snigdha father diagnosed lung cancer jul...</td>\n",
       "      <td>tarceva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>first recommended stanford oncologist last rec...</td>\n",
       "      <td>tarceva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mention recent development issue interest rega...</td>\n",
       "      <td>gilenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>course shortly posted everything good update b...</td>\n",
       "      <td>gilenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rituxan main drug rituxan technically approved...</td>\n",
       "      <td>ocrelizumab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>last updated january share comment tellafriend...</td>\n",
       "      <td>ocrelizumab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rebif year rotate injection site remember take...</td>\n",
       "      <td>fingolimod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>today post last threepart series burt stem cel...</td>\n",
       "      <td>gilenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>thanks everyone made feel alot better definite...</td>\n",
       "      <td>gilenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5251</th>\n",
       "      <td>dar nice news youand good news third ocrevus i...</td>\n",
       "      <td>ocrevus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5252</th>\n",
       "      <td>dear bmj glad hear loved one well tarceva bmj ...</td>\n",
       "      <td>tagrisso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5253</th>\n",
       "      <td>talking dmts relapsing remitting good comparis...</td>\n",
       "      <td>ocrelizumab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>tecfidera may available except scotland unless...</td>\n",
       "      <td>gilenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>urgh chilli con carne dinner followed massive ...</td>\n",
       "      <td>entyvio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5256</th>\n",
       "      <td>janet freemandaily cofounder rosders writing p...</td>\n",
       "      <td>tarceva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>end wheelchair lot people catastrophic reactio...</td>\n",
       "      <td>gilenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5258</th>\n",
       "      <td>thanks response edgarleroy found cladribine si...</td>\n",
       "      <td>cladribine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>introduction need effective safe treatment pre...</td>\n",
       "      <td>certolizumab pegol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5260</th>\n",
       "      <td>docetaxel week week week claim le harsh effica...</td>\n",
       "      <td>tarceva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5261</th>\n",
       "      <td>swollen lymph node good reason doctor look cou...</td>\n",
       "      <td>remicade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5262</th>\n",
       "      <td>couple people said remistart new name still ab...</td>\n",
       "      <td>remicade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5263</th>\n",
       "      <td>osimertinib cancer medicine interferes growth ...</td>\n",
       "      <td>osimertinib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5264</th>\n",
       "      <td>vitrectomy permanently affect vision like poor...</td>\n",
       "      <td>vitrectomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5265</th>\n",
       "      <td>oral fingolimod primary progressive multiple s...</td>\n",
       "      <td>fingolimod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>hello wife treated lung cancer tarceva blood w...</td>\n",
       "      <td>tarceva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>robert pray get good result wanted durvalumab ...</td>\n",
       "      <td>durvalumab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>cea number finger crossed also reading post us...</td>\n",
       "      <td>opdivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>started gilenya screening asked heart issue am...</td>\n",
       "      <td>gilenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>flare get worse time first flare indeed blood ...</td>\n",
       "      <td>humira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>choroidal neovascularization characteristic we...</td>\n",
       "      <td>photodynamic therapy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>jan jimp wrote think depends lot factor stage ...</td>\n",
       "      <td>opdivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>del also carry comparative simulation egfr com...</td>\n",
       "      <td>erlotinib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>bee thanks update good news scan hard say effe...</td>\n",
       "      <td>alimta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>blood testing done check level humira trough d...</td>\n",
       "      <td>entyvio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276</th>\n",
       "      <td>best husband family</td>\n",
       "      <td>opdivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>bazza luckily eye badly affected get headache ...</td>\n",
       "      <td>lucentis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>well appeared mild number year relapse taking ...</td>\n",
       "      <td>ocrevus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5279 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     autoimmune disease tend come cluster gilenya f...   \n",
       "1     completely understand would want try result re...   \n",
       "2     interesting target receptor rather like fingol...   \n",
       "3     interesting grand merci wonder lemtrada ocrevu...   \n",
       "4     everybody latest mri result brain cervical cor...   \n",
       "5     give advice lemtrada chose cladribine thought ...   \n",
       "6     reply posted jesszidek jess sorry read challen...   \n",
       "7     well expected neurologist want start tysabri k...   \n",
       "8     think fingolimod miserable failure progressive...   \n",
       "9     thank much learning lot grace mentioned husban...   \n",
       "10    vision one eye unrelated eye injection however...   \n",
       "11    significant bleeding right eye need laser poss...   \n",
       "12    objective review evidence supporting european ...   \n",
       "13    multiple sclerosis thought inflammatory proces...   \n",
       "14    mom diagnosis similar mine detected january ch...   \n",
       "15    humira adalimumab injectable protein antibody ...   \n",
       "16    well theory telling accurate standard practice...   \n",
       "17    goodness minnie really wish could use curse wo...   \n",
       "18    sebastian agreed entirely know alemtuzumab due...   \n",
       "19    good luck reg day ago went listen top neuro sp...   \n",
       "20    bmc ophthalmol jan intravitreal dexamethasone ...   \n",
       "21    father egfr exon insertion mutation found toda...   \n",
       "22    reply posted flower girl year got pregnant dau...   \n",
       "23    hello snigdha father diagnosed lung cancer jul...   \n",
       "24    first recommended stanford oncologist last rec...   \n",
       "25    mention recent development issue interest rega...   \n",
       "26    course shortly posted everything good update b...   \n",
       "27    rituxan main drug rituxan technically approved...   \n",
       "28    last updated january share comment tellafriend...   \n",
       "29    rebif year rotate injection site remember take...   \n",
       "...                                                 ...   \n",
       "5249  today post last threepart series burt stem cel...   \n",
       "5250  thanks everyone made feel alot better definite...   \n",
       "5251  dar nice news youand good news third ocrevus i...   \n",
       "5252  dear bmj glad hear loved one well tarceva bmj ...   \n",
       "5253  talking dmts relapsing remitting good comparis...   \n",
       "5254  tecfidera may available except scotland unless...   \n",
       "5255  urgh chilli con carne dinner followed massive ...   \n",
       "5256  janet freemandaily cofounder rosders writing p...   \n",
       "5257  end wheelchair lot people catastrophic reactio...   \n",
       "5258  thanks response edgarleroy found cladribine si...   \n",
       "5259  introduction need effective safe treatment pre...   \n",
       "5260  docetaxel week week week claim le harsh effica...   \n",
       "5261  swollen lymph node good reason doctor look cou...   \n",
       "5262  couple people said remistart new name still ab...   \n",
       "5263  osimertinib cancer medicine interferes growth ...   \n",
       "5264  vitrectomy permanently affect vision like poor...   \n",
       "5265  oral fingolimod primary progressive multiple s...   \n",
       "5266  hello wife treated lung cancer tarceva blood w...   \n",
       "5267  robert pray get good result wanted durvalumab ...   \n",
       "5268  cea number finger crossed also reading post us...   \n",
       "5269  started gilenya screening asked heart issue am...   \n",
       "5270  flare get worse time first flare indeed blood ...   \n",
       "5271  choroidal neovascularization characteristic we...   \n",
       "5272  jan jimp wrote think depends lot factor stage ...   \n",
       "5273  del also carry comparative simulation egfr com...   \n",
       "5274  bee thanks update good news scan hard say effe...   \n",
       "5275  blood testing done check level humira trough d...   \n",
       "5276                                best husband family   \n",
       "5277  bazza luckily eye badly affected get headache ...   \n",
       "5278  well appeared mild number year relapse taking ...   \n",
       "\n",
       "                              drug  \n",
       "0                          gilenya  \n",
       "1                          gilenya  \n",
       "2                       fingolimod  \n",
       "3                          ocrevus  \n",
       "4                          gilenya  \n",
       "5                       cladribine  \n",
       "6                           humira  \n",
       "7                          gilenya  \n",
       "8                       fingolimod  \n",
       "9                         tagrisso  \n",
       "10                        lucentis  \n",
       "11    pan-retinal photocoagulation  \n",
       "12                      fingolimod  \n",
       "13                         gilenya  \n",
       "14                        tagrisso  \n",
       "15                          humira  \n",
       "16                        remicade  \n",
       "17                         stelara  \n",
       "18                     ocrelizumab  \n",
       "19                         ocrevus  \n",
       "20                   dexamethasone  \n",
       "21                      pemetrexed  \n",
       "22                          cimzia  \n",
       "23                         tarceva  \n",
       "24                         tarceva  \n",
       "25                         gilenya  \n",
       "26                         gilenya  \n",
       "27                     ocrelizumab  \n",
       "28                     ocrelizumab  \n",
       "29                      fingolimod  \n",
       "...                            ...  \n",
       "5249                       gilenya  \n",
       "5250                       gilenya  \n",
       "5251                       ocrevus  \n",
       "5252                      tagrisso  \n",
       "5253                   ocrelizumab  \n",
       "5254                       gilenya  \n",
       "5255                       entyvio  \n",
       "5256                       tarceva  \n",
       "5257                       gilenya  \n",
       "5258                    cladribine  \n",
       "5259            certolizumab pegol  \n",
       "5260                       tarceva  \n",
       "5261                      remicade  \n",
       "5262                      remicade  \n",
       "5263                   osimertinib  \n",
       "5264                    vitrectomy  \n",
       "5265                    fingolimod  \n",
       "5266                       tarceva  \n",
       "5267                    durvalumab  \n",
       "5268                        opdivo  \n",
       "5269                       gilenya  \n",
       "5270                        humira  \n",
       "5271          photodynamic therapy  \n",
       "5272                        opdivo  \n",
       "5273                     erlotinib  \n",
       "5274                        alimta  \n",
       "5275                       entyvio  \n",
       "5276                        opdivo  \n",
       "5277                      lucentis  \n",
       "5278                       ocrevus  \n",
       "\n",
       "[5279 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
